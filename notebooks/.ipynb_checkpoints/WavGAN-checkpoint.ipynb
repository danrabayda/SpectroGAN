{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8083ee37-e358-49d4-9fc7-6725c5bf0248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 32000, 1), (16, 10), (16, 32000, 1), (16, 10))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import torch,torchvision\n",
    "from torch import nn\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_val_test_split(x,y,train_size=0.7):\n",
    "    x_trn,x_vts,y_trn,y_vts=train_test_split(x,y,test_size=1-train_size,stratify=y)\n",
    "    x_val,x_tst,y_val,y_tst=train_test_split(x_vts,y_vts,test_size=0.5,stratify=y_vts)\n",
    "\n",
    "data_folder='../data/raw/Kaggle_Environmental_Sound_Classification_50' \n",
    "sys.path.insert(0, os.path.abspath(data_folder))\n",
    "from utils import ESC50\n",
    "\n",
    "train_splits = [1,2,3,4]\n",
    "test_split = 5\n",
    "batch_size=16\n",
    "window_size_secs=2\n",
    "\n",
    "epochs = 200\n",
    "#sample_size = 64 # fixed sample size\n",
    "nz = 500 # latent vector size\n",
    "k = 1 # number of steps to apply to the discriminator\n",
    "\n",
    "shared_params = {'csv_path': data_folder+'/esc50.csv',\n",
    "                 'wav_dir': data_folder+'/audio/audio',\n",
    "                 'dest_dir': data_folder+'/audio/audio/16000',\n",
    "                 'audio_rate': 16000,\n",
    "                 'only_ESC10': True,\n",
    "                 'pad': 0,\n",
    "                 'normalize': True}\n",
    "\n",
    "train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=window_size_secs,\n",
    "                  mix=True,\n",
    "                  **shared_params).batch_gen(batch_size)\n",
    "\n",
    "test_gen = ESC50(folds=[test_split],\n",
    "                 randomize=False,\n",
    "                 strongAugment=False,\n",
    "                 random_crop=True,\n",
    "                 inputLength=window_size_secs,\n",
    "                 mix=False,\n",
    "                 **shared_params).batch_gen(batch_size)\n",
    "\n",
    "X, Y = next(train_gen)\n",
    "X2, Y2 = next(test_gen)\n",
    "X.shape, Y.shape, X2.shape, Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad75864-ccbd-44c2-80ba-97a5e42d93e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape=shared_params['audio_rate']*window_size_secs\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92edb19-e6ae-42e1-a269-3020ef0950d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator=nn.Sequential(nn.Linear(nz,data_shape//2**2),\n",
    "                          nn.LeakyReLU(0.2),\n",
    "                          # nn.Linear(data_shape//2**4,data_shape//2**3),\n",
    "                          # nn.LeakyReLU(0.2),\n",
    "                          # nn.Linear(data_shape//2**3,data_shape//2**2),\n",
    "                          # nn.LeakyReLU(0.2),\n",
    "                          # nn.Linear(data_shape//2**2,data_shape//2),\n",
    "                          # nn.LeakyReLU(0.2),\n",
    "                          nn.Linear(data_shape//2**2,data_shape),\n",
    "                          nn.Tanh())\n",
    "Discriminator=nn.Sequential(nn.Linear(data_shape,data_shape//2**3),\n",
    "                           nn.LeakyReLU(0.2),\n",
    "                           nn.Dropout(0.3),\n",
    "                           # nn.Linear(data_shape//2,data_shape//2**2),\n",
    "                           # nn.LeakyReLU(0.2),\n",
    "                           # nn.Dropout(0.3),\n",
    "                           # nn.Linear(data_shape//2**2,data_shape//2**3),\n",
    "                           # nn.LeakyReLU(0.2),\n",
    "                           # nn.Dropout(0.3),\n",
    "                           # nn.Linear(data_shape//2**3,data_shape//2**4),\n",
    "                           # nn.LeakyReLU(0.2),\n",
    "                           # nn.Dropout(0.3),\n",
    "                           # nn.Linear(data_shape//2**4,data_shape//2**5),\n",
    "                           # nn.LeakyReLU(0.2),\n",
    "                           # nn.Dropout(0.3),\n",
    "                           # nn.Linear(data_shape//2**5,data_shape//2**6),\n",
    "                           # nn.LeakyReLU(0.2),\n",
    "                           # nn.Dropout(0.3),\n",
    "                           nn.Linear(data_shape//2**3,data_shape//2**7),\n",
    "                           nn.LeakyReLU(0.2),\n",
    "                           nn.Dropout(0.3),\n",
    "                           nn.Linear(data_shape//2**7,1),\n",
    "                           nn.Sigmoid())\n",
    "generator=Generator.to(device)\n",
    "discriminator=Discriminator.to(device)\n",
    "\n",
    "optim_g = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optim_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "criterion=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb726bb4-9b63-4812-a783-306f515566f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)\n",
    "# function to create the noise vector\n",
    "def create_noise(sample_size, nz):\n",
    "    return torch.randn(sample_size, nz).to(device)\n",
    "\n",
    "# function to train the discriminator network\n",
    "def train_discriminator(optimizer, data_real, data_fake):\n",
    "    b_size = data_real.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "    fake_label = label_fake(b_size)\n",
    "    optimizer.zero_grad()\n",
    "    output_real = discriminator(data_real)\n",
    "    loss_real = criterion(output_real, real_label)\n",
    "    output_fake = discriminator(data_fake)\n",
    "    loss_fake = criterion(output_fake, fake_label)\n",
    "    loss_real.backward()\n",
    "    loss_fake.backward()\n",
    "    optimizer.step()\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "# function to train the generator network\n",
    "def train_generator(optimizer, data_fake):\n",
    "    b_size = data_fake.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "    optimizer.zero_grad()\n",
    "    output = discriminator(data_fake)\n",
    "    loss = criterion(output, real_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "losses_g=[]\n",
    "losses_d=[]\n",
    "noise = create_noise(batch_size, nz)\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706580f2-c703-450b-a671-3773fc43e50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=500, out_features=8000, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Linear(in_features=8000, out_features=32000, bias=True)\n",
       "  (3): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125b7d30-7045-4d9d-a630-2aed396a86c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=32000, out_features=4000, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Dropout(p=0.3, inplace=False)\n",
       "  (3): Linear(in_features=4000, out_features=250, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.2)\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Linear(in_features=250, out_features=1, bias=True)\n",
       "  (7): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e449af-ff9b-4536-a9ff-54e9248f1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    loss_g = 0.0\n",
    "    loss_d = 0.0\n",
    "    for bi, data in enumerate(train_gen):\n",
    "        samps, _ = data\n",
    "        samps=torch.tensor(samps)\n",
    "        samps = samps.to(device)\n",
    "        b_size = len(samps)\n",
    "        # run the discriminator for k number of steps\n",
    "        for step in range(k):\n",
    "            n=create_noise(b_size, nz)\n",
    "            data_fake = generator(n).detach()\n",
    "            data_real = samps.reshape(samps.shape[:-1]).float()\n",
    "            # train the discriminator network\n",
    "            loss_d += train_discriminator(optim_d, data_real, data_fake)\n",
    "        data_fake = generator(create_noise(b_size, nz))\n",
    "        # train the generator network\n",
    "        loss_g += train_generator(optim_g, data_fake)\n",
    "    # create the final fake signal for the epoch\n",
    "    generated_s = generator(noise).cpu().detach()\n",
    "    # make the samps as grid\n",
    "    generated_s = make_grid(generated_s)\n",
    "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
    "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
    "    losses_g.append(epoch_loss_g)\n",
    "    losses_d.append(epoch_loss_d)\n",
    "    \n",
    "    print(f\"Epoch {epoch} of {epochs}\")\n",
    "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef43d3-0924-4a0d-8e5b-87ec2c7bbfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
